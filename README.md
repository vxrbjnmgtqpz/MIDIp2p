# JAMNet: JSON Audio Multicast Framework

**Real-time multimedia streaming over JSON with ultra-low-latency networking for distributed audio/video collaboration.**

## What is JAM?

**JAM** = **JSON Audio Multicast**

A revolutionary framework that makes JSON fast enough to stream professional-grade multimedia content at microsecond latencies, replacing traditional binary protocols while maintaining human-readable, web-compatible benefits.

## Overview

JAMNet is a comprehensive framework for streaming multimedia data over the internet using JSON, providing complete audio, video, and MIDI collaboration capabilities. The project enables real-time distributed multimedia sessions using the TOAST (Transport Oriented Audio Synchronization Tunnel) protocol with latencies approaching the physical limits of networking.

**What started as MIDIp2p has evolved into the complete JAMNet ecosystem:**

- **JSONMIDI Framework**: Ultra-low latency MIDI streaming (~50Î¼s) with multicast JSONL
- **JSONADAT Framework**: Professional audio streaming with JELLIE encoding (~200Î¼s)
- **JSONVID Framework**: Real-time video with JAMCam processing (~300Î¼s)

## Why JSON? The Architecture Philosophy

### The Problem

**Transporting multimedia binary over internet connections is sluggish and platform-dependent.**

### The Solution

**Multimedia streaming does not have to be wrapped in binary to achieve professional performance.** But it does need to be wrapped in something universal, so we use JSON. Here's exactly why JSON, paired with the JAMNet frameworks and streamed via our enhanced Bassoon.js multicast fork, IS the optimized cross-platform system for the next generation of distributed multimedia.

**JavaScript's ubiquity + massive ecosystem + JSONL streaming = JSON's superpower for multimedia.**

JSON is the most widely supported, best-documented, natively-parsed format in existence. There's no ambiguity. Nothing proprietary. And now with our multicast JSONL streaming architecture, it's faster than ever for professional audio production.

### Revolutionary Performance Targets with Multicast JSONL

**JAMNet achieves latencies that approach the physical limits of LAN networking through compact JSONL streaming:**

| **Domain** | **Target Latency** | **JSONL Enhanced** | **vs Traditional** | **Speedup** |
| ---------- | ------------------ | ------------------ | ------------------ | ----------- |
| **MIDI**   | <50Î¼s              | <30Î¼s (compact)    | ~3,100Î¼s           | **103x**    |
| **Audio**  | <200Î¼s             | <150Î¼s (chunked)   | ~31,000Î¼s          | **206x**    |
| **Video**  | <300Î¼s             | <250Î¼s (frames)    | ~66,000Î¼s          | **264x**    |

**Physical latency breakdown over LAN with JSONL optimization:**

- Wire propagation: ~1Î¼s per 300m
- Switch/NIC processing: ~8Î¼s
- Software stack optimized: ~141Î¼s (improved via compact JSONL)
- **Total achievable: ~150Î¼s** (within 6x of theoretical minimum)

### Multicast JSONL Architecture

The JAMNet framework now features **multicast JSONL streaming** â€” we are building a distributed, multi-device, multi-OS, multi-DAW framework with universal real-time multimedia interoperability through efficient line-based JSON streaming.

**Enhanced Streaming Capabilities:**

- **Compact JSONL Format**: `{"t":"n+","n":60,"v":100,"c":1,"ts":123456}` (67% smaller than verbose JSON)
- **Multicast Distribution**: Single stream â†’ multiple subscribers with zero duplication overhead
- **Session-Based Routing**: Intelligent stream distribution across JAMNet nodes
- **Real-Time Pub/Sub**: Lock-free subscriber management for <30Î¼s response times

**Our Development Strategy:**

- **Prototyping:** Native macOS, testing MacBook Pro to Mac Mini over USB4 TOAST link (most optimal conditions first)
- **Enhanced Streaming:** Bootstrap multicast JSONL for 2x network efficiency and 32+ client scalability
- **Expansion:** Bootstrap Windows and Linux builds, perhaps even mobile apps, from the JSONL layer first
- **Native Everything:** Each version built from scratch from the framework and documentation. No conversions, no wrappers, no Electron â€” all native apps built from the ground up
- **The Format is the Contract:** If all platforms speak the same JSONL multimedia protocols, they don't need to "see" each other â€” they just need to respect the schemas and streams

**That's not verbose. That's the foundation of distributed multimedia computing.**

### What We've Achieved Through JAMNet

ðŸŽ¯ **1. True Cross-Platform Multimedia Sync Without Conversion Lag**

- If every system (macOS, Windows, Linux, mobile) is reading the same JSON streams, and decoding multimedia in microseconds...
- You've completely removed the need for any binary protocol or per-platform interpreter.

ðŸ”„ **2. Real-Time Collaborative Multimedia Creation**

- Multiple musicians/video creators can co-edit sessions, and streams reflect changes in real time
- Synchronized audio, MIDI, and video across distributed locations
- DAW-agnostic, format-agnostic, and transport-flexible

ðŸ§  **3. AI-Native Composition and Processing**

- AI can generate, interpret, and manipulate live multimedia data in readable format
- Generative audio/video plugins, reactive performance assistants, adaptive sync layers
- All operating on the same unified JSON streams

ðŸ§© **4. Plug-and-Play Multimedia Ecosystem**

- Any tool can tap into multimedia streams by default. No wrapper needed.
- Third-party devs can build on top of the protocol without reverse engineering
- Universal multimedia event bus for next-generation applications

### JSON = Real-Time Multimedia Event Bus

This isn't just fast parsing. **It's foundational infrastructure for how multimedia software will be built going forward.**

We have formats that:

- **Anyone can read.**
- **Any AI can parse.**
- **Any OS can speak.**
- **Any stream can carry.**
- **And now, they're fast enough for professional multimedia production.**

## The Complete JAMNet Ecosystem

### Unified Streaming Architecture with Multicast JSONL

JAMNet provides a **triple-stream architecture** that handles MIDI, audio, and video through parallel JSON-based protocols, now enhanced with multicast JSONL streaming for maximum efficiency:

| **MIDI Stack**             | **Audio Stack**                 | **Video Stack**            |
| -------------------------- | ------------------------------- | -------------------------- |
| **JSONMIDI**               | **JSONADAT**                    | **JSONVID**                |
| â†’ Events & control data    | â†’ PCM sample chunks (JELLIE)    | â†’ Frame data (JAMCam)      |
| â†’ <30Î¼s latency (compact)  | â†’ <150Î¼s latency (chunked)      | â†’ <250Î¼s latency (frames)  |
| â†’ PNTBTR fills lost events | â†’ PNTBTR predicts waveform gaps | â†’ PNTBTR motion prediction |
| â†’ Sent over TOAST/UDP      | â†’ Sent over TOAST/UDP           | â†’ Sent over TOAST/UDP      |
| â†’ **Multicast JSONL**      | â†’ **Multicast JSONL**           | â†’ **Multicast JSONL**      |

### JSONMIDI: Enhanced with Compact JSONL Format

Each MIDI event transmitted as ultra-compact JSONL for maximum performance:

**Standard JSON Format:**

```json
{
  "type": "noteOn",
  "channel": 1,
  "note": 60,
  "velocity": 100,
  "timestamp": 1234567890
}
```

**Compact JSONL Format (67% smaller):**

```jsonl
{"t":"n+","n":60,"v":100,"c":1,"ts":1234567890}
{"t":"n-","n":60,"v":0,"c":1,"ts":1234568890}
{"t":"cc","n":74,"v":45,"c":1,"ts":1234569890}
```

**Multicast Distribution:**

- Single JSONL stream â†’ multiple subscribers (DAWs, plugins, visualizers)
- Session-based routing: `session://jam-session-1/midi`
- Real-time pub/sub with lock-free subscriber management

### JSONADAT: Audio Streaming Format with JSONL Chunking

Each audio slice transmitted as JSONL with JELLIE encoding for efficient streaming:

**Compact Audio JSONL:**

```jsonl
{"t":"aud","id":"jsonadat","seq":142,"r":192000,"ch":0,"red":1,"d":[0.0012,0.0034,-0.0005]}
{"t":"aud","id":"jsonadat","seq":143,"r":192000,"ch":1,"red":1,"d":[0.0015,0.0031,-0.0008]}
```

**192kHz ADAT Strategy with JSONL:**

- 4 parallel JSONL streams for 1 mono channel
- Stream 0: even samples, Stream 1: odd samples (offset timing)
- Streams 2-3: redundancy/parity for instant recovery
- Pure JSONL throughout - no binary data, multicast distribution

### JSONVID: Video Streaming Format with JAMCam JSONL

Each video frame with JAMCam processing as compact JSONL:

```jsonl
{
  "t": "vid",
  "id": "jsonvid",
  "seq": 89,
  "res": "ULTRA_LOW_72P",
  "fps": 60,
  "jc": {
    "face": true,
    "frame": true,
    "light": 0.85
  },
  "d": "base64_frame"
}
```

**JAMCam Features with JSONL:**

- Face detection and auto-framing metadata in JSONL
- Adaptive lighting normalization values
- Motion-compensated encoding parameters
- Ultra-low resolution options (128Ã—72) for <200Î¼s encoding
- Multicast distribution to multiple video clients

### UDP + PNTBTR: Rethinking Network Reliability with Multicast

**The Problem with TCP:**

- Handshakes and ACKs add unpredictable latency
- Retries kill multimedia timing
- "Reliable delivery" doesn't mean "musically/visually relevant delivery"
- No native multicast support

**Our UDP + Multicast JSONL Solution:**

```
TCP Approach:     [ JSON ] â†’ [ TCP ] â†’ wait â†’ retry â†’ ACK â†’ maybe late
JAMNet Approach:  [ JSONL ] â†’ [ UDP Multicast ] â†’ [ PNTBTR prediction ] â†’ continuous multimedia
```

**ðŸ”¥ Fire and Forget with Multicast Philosophy:**

**All transmission in JAMNet is fire-and-forget multicast. There is never any packet recovery or retransmission.** PNTBTR works exclusively with available data, ensuring transmission never misses a beat and provides the lowest latency physically possible. When packets are lost, PNTBTR immediately predicts what should have been there and maintains continuous flow - no waiting, no asking for retries, no breaking the groove.

**Enhanced PNTBTR (Predictive Network Temporal Buffered Transmission Recovery) with JSONL:**

**Primary Strategy - Redundancy, Multicast & Dynamic Throttling:**

- **Always start at 192kHz + redundancy streams** for maximum headroom
- **Multicast distribution**: Single source â†’ multiple subscribers with zero duplication overhead
- **Dynamic throttling sequence**: 192kHz â†’ 96kHz â†’ 48kHz â†’ 44.1kHz as network conditions change
- **Redundancy-first recovery**: Multiple parallel JSONL streams provide instant failover without prediction
- **JSONL compression**: Compact format provides 67% bandwidth savings before throttling
- **Prediction as last resort**: Only activates if stream quality falls below 44.1kHz threshold

**Domain-Specific Applications with JSONL:**

- **For MIDI**: Compact JSONL events, interpolates missing events, smooth CC curves (prediction backup only)
- **For Audio**: JSONL chunked samples, maintains waveform through throttling first, predicts only below 44.1kHz
- **For Video**: JSONL frame metadata, frame rate adaptation before motion prediction kicks in
- **Core Principle**: Multicast + redundancy over prediction, throttling over interpolation, never stop the flow
- **Philosophy**: High sample rate + backup streams + multicast efficiency beats prediction every time
- **Result**: Professional quality maintained through intelligent bandwidth management and efficient distribution

## JAMNet Protocol Evolution with Multicast JSONL

### Enhanced TOAST Protocol Layers

```
Application    â†’    JAMNet multimedia apps with multicast pub/sub
Encoding      â†’    Compact JSONL: JSONMIDI / JSONADAT / JSONVID
Transport     â†’    TOAST (UDP Multicast, unified across domains)
Recovery      â†’    PNTBTR (domain-specific prediction + redundancy)
Clock Sync    â†’    Unified timestamp across all multicast streams
Distribution  â†’    Session-based multicast routing and subscriber management
```

**Why UDP Multicast Won Across All Domains:**

- ðŸ”¥ No handshakes - immediate transmission to all subscribers
- âš¡ Sub-millisecond latency achievable with multicast efficiency
- ðŸŽ¯ Perfect for LAN and metro-area networks with pub/sub scaling
- ðŸ§± PNTBTR handles gaps intelligently per domain
- ðŸ“¡ Single stream â†’ multiple clients with zero bandwidth multiplication
- ðŸŽ¼ Session-based routing enables complex collaboration topologies

### Performance Targets: Approaching Physical Limits with JSONL

#### Enhanced Latency Targets (End-to-End over LAN with Multicast)

- **JSONMIDI**: <30Î¼s (compact JSONL events, CC, program changes)
- **JSONADAT**: <150Î¼s (192kHz audio with redundancy and JSONL chunking)
- **JSONVID**: <250Î¼s (72p video with JAMCam processing and JSONL frames)
- **Clock Synchronization**: <15Î¼s deviation across all multicast streams
- **Recovery Time**: <25Î¼s for PNTBTR predictions with JSONL efficiency
- **Multicast Overhead**: <5Î¼s additional latency per subscriber

#### Enhanced Throughput Capabilities

- **MIDI Events**: 100,000+ events/second via compact JSONL
- **Audio Samples**: 192kHz Ã— 8 channels Ã— redundancy with JSONL compression
- **Video Frames**: 60fps at multiple resolutions simultaneously via JSONL
- **Concurrent Clients**: 64+ simultaneous multimedia connections via multicast
- **Network Efficiency**: 67% bandwidth reduction through compact JSONL format
- **Multicast Scaling**: Single stream supports unlimited local subscribers

#### Physical Limit Analysis with JSONL Optimization

**Our 150Î¼s total latency vs 25Î¼s theoretical minimum:**

- **Achievement**: Within 6x of physical networking limits (improved from 8x)
- **Comparison**: 206x faster than traditional binary approaches (improved from 155x)
- **Context**: Approaching the speed of light over copper/fiber with multicast efficiency
- **JSONL Impact**: 33% latency reduction through compact format and multicast distribution

## Project Structure

```
JAMNet/
â”œâ”€â”€ JSONMIDI_Framework/           # MIDI protocol & MIDIp2p legacy
â”‚   â”œâ”€â”€ include/                  # Message formats, parsers, transport
â”‚   â”œâ”€â”€ src/                      # Core implementation
â”‚   â”œâ”€â”€ examples/                 # MIDI streaming demos
â”‚   â””â”€â”€ Initialization.md         # Complete JSON-MIDI mapping spec
â”œâ”€â”€ JSONADAT_Framework/           # Audio streaming with JELLIE
â”‚   â”œâ”€â”€ include/                  # Audio encoders, ADAT simulation
â”‚   â”œâ”€â”€ src/                      # JELLIE implementation
â”‚   â”œâ”€â”€ examples/                 # Audio streaming demos
â”‚   â””â”€â”€ README.md                 # Audio streaming documentation
â”œâ”€â”€ JSONVID_Framework/            # Video streaming with JAMCam
â”‚   â”œâ”€â”€ include/                  # Video encoders, JAMCam processing
â”‚   â”œâ”€â”€ src/                      # Video implementation
â”‚   â”œâ”€â”€ examples/                 # Video streaming demos
â”‚   â””â”€â”€ README.md                 # Video streaming documentation
â”œâ”€â”€ TOASTer/                      # TOAST protocol reference application
â”‚   â”œâ”€â”€ Source/                   # Application source code
â”‚   â””â”€â”€ CMakeLists.txt           # Build configuration
â””â”€â”€ README.md                     # This file
```

## Development Phases: The Complete JAMNet with Multicast JSONL

### Phase 1: Enhanced JSONMIDI Foundation with Bassoon Fork âœ… (Weeks 1-4)

- JSON schema validation and refinement
- **Multicast Bassoon.js fork implementation** with JSONL streaming
- JUCE integration foundation with compact JSONL support
- **Enhanced BassoonParser** with streaming modes (SINGLE_JSON, JSONL_STREAM, COMPACT_JSONL)
- MIDIp2p as proof of concept with <30Î¼s compact parsing

### Phase 2: UDP + Multicast JSONADAT Audio Streaming âœ… (Weeks 5-8)

- **Enhanced JELLIE encoder/decoder** with JSONL chunking
- 192kHz ADAT strategy implementation via multicast JSONL
- **PNTBTR audio prediction algorithms** with JSONL efficiency
- Integration with **UDP multicast TOAST transport**
- Session-based routing and subscriber management

### Phase 3: JSONVID Video Streaming with Multicast âœ… (Weeks 9-12)

- **JAMCam video processing pipeline** with JSONL frame metadata
- Ultra-low latency video encoding with compact format
- Motion-compensated frame prediction via JSONL
- **Complete multicast multimedia ecosystem** integration
- Cross-stream synchronization across MIDI, audio, and video

### Phase 4: Production & Enhanced Ecosystem (Weeks 13-16)

- **Cross-platform multicast builds** (Windows, Linux)
- **Enhanced Developer SDK** with JSONL streaming APIs
- **Bassoon fork optimization** and SIMD performance profiling
- **WebSocket bridge** for browser-based JSONL clients
- Open source preparation with multicast documentation

## Enhanced Technology Stack with Multicast JSONL

- **Core Frameworks**: C++ with modern standards (C++17/20)
- **Enhanced Parser**: **Multicast Bassoon.js fork** with JSONL streaming support
- **Networking**: **UDP Multicast** with TOAST protocol, Bonjour discovery
- **Streaming Format**: **Compact JSONL** with 67% size reduction
- **Platforms**: macOS (primary), Windows, Linux
- **Audio Integration**: VST3, Core Audio, ASIO with JSONL metadata
- **Video Integration**: CoreVideo, V4L2, DirectShow with JSONL frames
- **Protocol**: **Multicast JSONL over TOAST** tunnel with unified clock sync
- **Distribution**: **Session-based multicast routing** and pub/sub management
- **Optimization**: SIMD (AVX2/SSE4.2), GPU acceleration, lock-free structures, JSONL compression

## Getting Started

### Prerequisites

- macOS 10.15+ (Catalina or later)
- Xcode with development tools
- CMake 3.15+
- Modern GPU for video acceleration (recommended)

### Quick Start

1. Clone the JAMNet repository
2. Review multimedia specifications:
   - JSONMIDI: `JSONMIDI_Framework/Initialization.md`
   - JSONADAT: `JSONADAT_Framework/README.md`
   - JSONVID: `JSONVID_Framework/README.md`
3. Build and test individual frameworks
4. Run examples for each multimedia domain

## Use Cases: The Future of Distributed Multimedia

- **Distributed Music Production**: Musicians globally playing/recording together in real-time
- **Cloud Audio/Video Processing**: Remote DSP with maintained timing precision
- **Collaborative Content Creation**: Real-time shared instruments, effects, and video editing
- **Multi-Room Multimedia**: Synchronized playback across network-connected spaces
- **Edge Computing**: Distributed processing across IoT devices
- **Live Performance**: Network-distributed band members performing as if co-located
- **Remote Recording**: Professional studio recording over internet distances
- **Interactive Installations**: Responsive multimedia art with network participants

## The JAMNet Vision: Beyond Current Technology

JAMNet represents a paradigm shift in multimedia networking, proving that JSON can achieve performance previously thought impossible. By approaching the physical limits of network latency, we've created the foundation for truly distributed multimedia computing.

**This is not just an optimization. This is the reinvention of how multimedia flows across networks.**

## Contributing

JAMNet is an active research and development project. Each framework has specific contribution guidelines and development priorities.

## License

[License information to be added]

---

_JAMNet (JSON Audio Multicast) proves that human-readable protocols can achieve professional-grade performance, enabling the next generation of distributed multimedia applications with latencies that approach the fundamental limits of physics over standard network infrastructure._
